* **Paper Title** <br>
*Author(s)* <br>
Conference, Year. [[Paper]](link) [[Code]](link) [[Website]](link)


# [Text 2 Image](https://www.bilibili.com/video/BV17r4y1u77B?spm_id_from=333.999.0.0&vd_source=748e2ffada3badcc315a8de5269e2580)
| Name  | pdf  |   github |
| :--- |:--- |:---: |
| DALLE  |[Zero-Shot Text-to-Image Generation](https://arxiv.org/pdf/2102.12092) |  [github](https://github.com/lucidrains/DALLE-pytorch) |
| CogView |[CogView: Mastering Text-to-Image Generation via Transformers](https://arxiv.org/pdf/2105.13290.pdf) |[github](https://github.com/THUDM/CogView) |
| N\"UWA |[NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion](https://arxiv.org/pdf/2111.12417.pdf) |[github](https://github.com/lucidrains/nuwa-pytorch) |
| GLIDE |[GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models](https://arxiv.org/pdf/2112.10741v3.pdf) | [github](https://github.com/openai/glide-text2im) |
| ERNIE-ViLG  |[ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation](https://arxiv.org/pdf/2112.15283.pdf) |  [github](https://github.com/PaddlePaddle/FleetX) |
| DALL·E 2 |[Hierarchical Text-Conditional Image Generation with CLIP Latents](https://cdn.openai.com/papers/dall-e-2.pdf) | |
| CogView2 |[CogView: Mastering Text-to-Image Generation via Transformers](https://arxiv.org/pdf/2105.13290.pdf) |[github](https://github.com/THUDM/CogView2)|
| CogVideo |[CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://arxiv.org/pdf/2205.15868.pdf) |[github]() |
| Imagen |[Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://arxiv.org/pdf/2205.11487.pdf) |[github](https://github.com/lucidrains/imagen-pytorch) |

* **Compositional Visual Generation with Composable Diffusion Models** <br>
*Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, Joshua B. Tenenbaum* <br>
ECCV, 2022. [[Paper]](https://arxiv.org/pdf/2206.01714.pdf) [[Code]](https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch) [[Website]](https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/)


# [dalle-mini](https://huggingface.co/spaces/dalle-mini/dalle-mini)

# [李沐读论文](https://github.com/mli/paper-reading)

# awesome-embodied-intelligent
awesome-embodied-intelligent related

## [awesome-embodied-vision](https://github.com/ChanganVR/awesome-embodied-vision)

## [awesome-audio-visual](https://github.com/krantiparida/awesome-audio-visual)

## [awesome-egocentric-vision](https://github.com/Sid2697/awesome-egocentric-vision)

## [habitat-imitation-baselines](https://github.com/Ram81/habitat-imitation-baselines)

Thanks to Changan, krantiparida , Sid2697 and Ram81 for their hard work！

# Others

## [Awesome-Diffusion-Models](https://github.com/heejkoo/Awesome-Diffusion-Models)

## [DiffusionCLIP](https://github.com/gwang-kim/DiffusionCLIP)

## [Awesome-AAAI2022-Low-Level-Vision](https://github.com/DarrenPan/Awesome-AAAI2022-Low-Level-Vision)


Thanks to heejkoo, gwang-kim ,and DarrenPan  for their hard work！

[Zhenyu Tang](https://scholar.google.com/citations?user=gPGVGTkAAAAJ&hl=en)


[Changan Chen](https://changan.io/)

**Building and Evaluation of a Real Room Impulse Response Dataset**

  _Szöke I, Skácel M, Mošner L, et al._

  IEEE Journal of Selected Topics in Signal Processing, 2019. [[Paper]](https://arxiv.org/pdf/1811.06795) [Code] [Website]



**StoRIR: Stochastic Room Impulse Response Generation For Audio Data Augmentation**

  _Masztalski P, Matuszewski M, Piaskowski K, et al._

  arXiv, 2020. [[Paper]](https://arxiv.org/pdf/2008.07231) [[Code]](https://github.com/SRPOL-AUI/storir) [Website]


**IR-GAN: Room Impulse Response Generator for Far-field Speech Recognition**

  _Ratnarajah A, Tang Z, Manocha D._

  arXiv, 2020. [[Paper]](https://arxiv.org/pdf/2010.13219) [[Code]](https://github.com/GAMMA-UMD/IR-GAN) [[Website]](https://www.youtube.com/watch?v=_v5rDmDXvD0)

  **gpuRIR: A Python Library for Room Impulse Response Simulation with GPU Acceleration**

  _Diaz-Guerra D, Miguel A, Beltran J R.._

  Multimedia Tools and Applications, 2021. [[Paper]](https://arxiv.org/pdf/1810.11359) [[Code]](https://github.com/DavidDiazGuerra/gpuRIR) [Website]

  **TS-RIR: Translated synthetic room impulse responses for speech augmentation**

  _Ratnarajah A, Tang Z, Manocha D._

  IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2021. [[Paper]](https://arxiv.org/pdf/2103.16804) [[Code]](https://github.com/GAMMA-UMD/TS-RIR) [[Website]](https://www.youtube.com/watch?v=gghzIMT8FCw)
  

**Geometry-Aware Multi-Task Learning for Binaural Audio Generation from Video**

  _Garg R, Gao R, Grauman K._

  arXiv, 2021. [[Paper]](https://arxiv.org/pdf/2111.10882) [Code] [[Website]](https://www.youtube.com/watch?v=rTLMcH4QUKI)

**MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes**

  _Ratnarajah A, Tang Z, Aralikatti R C, et al._

  arXiv, 2022. [[Paper]](https://arxiv.org/pdf/2205.09248) [[Code]](https://github.com/anton-jeran/MESH2IR) [[Website]](https://anton-jeran.github.io/M2IR/)

**Few-Shot Audio-Visual Learning of Environment Acoustics**

  _Majumder S, Chen C, Al-Halah Z, et al._

   arXiv, 2022. [[Paper]](https://arxiv.org/pdf/2206.04006) [Code] [[Website]](https://vision.cs.utexas.edu/projects/fs_rir/)

**FAST-RIR: Fast neural diffuse room impulse response generator**

  _Ratnarajah A, Zhang S X, Yu M, et al._

  IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2022. [[Paper]](https://arxiv.org/pdf/2110.04057) [[Code]](https://github.com/anton-jeran/FAST-RIR) [[Website]](https://anton-jeran.github.io/FRIR/)
