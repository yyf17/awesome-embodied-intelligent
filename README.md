# [Text 2 Image](https://www.bilibili.com/video/BV17r4y1u77B?spm_id_from=333.999.0.0&vd_source=748e2ffada3badcc315a8de5269e2580)
| Name  | pdf  |   github |
| :--- |:--- |:---: |
| DALLE  |[Zero-Shot Text-to-Image Generation](https://arxiv.org/pdf/2102.12092) |  [github](https://github.com/lucidrains/DALLE-pytorch) |
| CogView |[CogView: Mastering Text-to-Image Generation via Transformers](https://arxiv.org/pdf/2105.13290.pdf) |[github](https://github.com/THUDM/CogView) |
| N\"UWA |[NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion](https://arxiv.org/pdf/2111.12417.pdf) |[github](https://github.com/lucidrains/nuwa-pytorch) |
| GLIDE |[GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models](https://arxiv.org/pdf/2112.10741v3.pdf) | [github](https://github.com/openai/glide-text2im) |
| ERNIE-ViLG  |[ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation](https://arxiv.org/pdf/2112.15283.pdf) |  [github](https://github.com/PaddlePaddle/FleetX) |
| DALL·E 2 |[Hierarchical Text-Conditional Image Generation with CLIP Latents](https://cdn.openai.com/papers/dall-e-2.pdf) | |
| CogView2 |[CogView: Mastering Text-to-Image Generation via Transformers](https://arxiv.org/pdf/2105.13290.pdf) |[github](https://github.com/THUDM/CogView2)|
| CogVideo |[CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://arxiv.org/pdf/2205.15868.pdf) |[github]() |
| Imagen |[Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://arxiv.org/pdf/2205.11487.pdf) |[github](https://github.com/lucidrains/imagen-pytorch) |




# [dalle-mini](https://huggingface.co/spaces/dalle-mini/dalle-mini)

# [李沐读论文](https://github.com/mli/paper-reading)

# awesome-embodied-intelligent
awesome-embodied-intelligent related

## [awesome-embodied-vision](https://github.com/ChanganVR/awesome-embodied-vision)

## [awesome-audio-visual](https://github.com/krantiparida/awesome-audio-visual)

## [awesome-egocentric-vision](https://github.com/Sid2697/awesome-egocentric-vision)

## [habitat-imitation-baselines](https://github.com/Ram81/habitat-imitation-baselines)

Thanks to Changan, krantiparida , Sid2697 and Ram81 for their hard work！

# Others

## [Awesome-Diffusion-Models](https://github.com/heejkoo/Awesome-Diffusion-Models)

## [DiffusionCLIP](https://github.com/gwang-kim/DiffusionCLIP)

## [Awesome-AAAI2022-Low-Level-Vision](https://github.com/DarrenPan/Awesome-AAAI2022-Low-Level-Vision)


Thanks to heejkoo, gwang-kim ,and DarrenPan  for their hard work！

[Zhenyu Tang](https://scholar.google.com/citations?user=gPGVGTkAAAAJ&hl=en)


[Changan Chen](https://changan.io/)
